# ğŸ›¡ï¸ Detector de Toxicidad con TensorFlow

Este proyecto implementa un detector de toxicidad en tiempo real utilizando TensorFlow.js y React, desarrollado por [smesa-leantech](https://github.com/smesa-leantech/toxicity-detector-tensorflow).

## âœ¨ CaracterÃ­sticas

- AnÃ¡lisis de texto en tiempo real
- Interfaz de usuario moderna y responsive usando Shadcn/ui
- VisualizaciÃ³n de resultados mediante grÃ¡ficos
- Soporte para mÃºltiples categorÃ­as de toxicidad:
  - Toxicidad general
  - Insultos
  - Amenazas
  - Lenguaje explÃ­cito
  - Identidad de odio
  - Obscenidad

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Frontend**: 
  - React + TypeScript + Vite
  - TailwindCSS para estilos
- **ML**: TensorFlow.js
- **UI Components**: 
  - Shadcn/ui
  - Radix UI para componentes accesibles
- **GrÃ¡ficos**: Recharts
- **Utilidades**:
  - Lucide para iconos
  - CMDK para comandos
  - Vaul para drawers

## ğŸš€ InstalaciÃ³n

1. Clona el repositorio:
````bash
git clone https://github.com/smesa-leantech/toxicity-detector-tensorflow.git
````

2. Instala las dependencias:
````bash
cd toxicity-detector-tensorflow
npm install
````

3. Inicia el servidor de desarrollo:
````bash
npm run dev
````

## ğŸ“ Estructura del Proyecto

````
src/
â”œâ”€â”€ app/                    # Rutas y pÃ¡ginas principales
â”‚   â””â”€â”€ public/            # PÃ¡ginas pÃºblicas
â”‚       â””â”€â”€ toxicity-detector/  # MÃ³dulo principal
â”œâ”€â”€ components/            # Componentes reutilizables
â”‚   â””â”€â”€ ui/               # Componentes de interfaz de usuario
â”œâ”€â”€ modules/              # LÃ³gica de negocio
â””â”€â”€ assets/              # Recursos estÃ¡ticos
````

## ğŸ’¡ Uso

1. Accede a la pÃ¡gina principal del detector
2. Ingresa el texto que deseas analizar
3. El modelo procesarÃ¡ el texto en tiempo real
4. Visualiza los resultados del anÃ¡lisis de toxicidad

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Por favor:

1. Haz fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/NuevaCaracteristica`)
3. Commit tus cambios (`git commit -m 'Agrega nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/NuevaCaracteristica`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- TensorFlow.js por el modelo de detecciÃ³n de toxicidad
- Shadcn/ui por los componentes de interfaz
- La comunidad de cÃ³digo abierto

## ğŸ“§ Contacto

Para preguntas y soporte, por favor abre un issue en el [repositorio](https://github.com/smesa-leantech/toxicity-detector-tensorflow).

---

â­ï¸ Si este proyecto te ha sido Ãºtil, considera darle una estrella en GitHub!
